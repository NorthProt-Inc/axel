{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-001","location":"docs/plan/axel-project-plan.md:594","current":"embeddingDimension: z.number().int().default(768)","expected":"embeddingDimension: z.number().int().default(3072)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43 — Mark confirms full 3072d, NOT truncated 768d"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-002","location":"docs/plan/axel-project-plan.md:770","current":"embedding vector(768) NOT NULL -- pgvector: 768d (Gemini embedding-001)","expected":"embedding vector(3072) NOT NULL -- pgvector: 3072d (Gemini embedding-001)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-003","location":"docs/plan/axel-project-plan.md:978-979","current":"axnmihn: ChromaDB (별도 프로세스), 768d / Axel: pgvector (같은 DB), 768d","expected":"Axel line should read 3072d (axnmihn historical reference 768d is correct)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-004","location":"docs/plan/axel-project-plan.md:1705","current":"ChromaDB (1000+ vectors, 768d) → pgvector (re-embed or direct copy)","expected":"pgvector target should specify 3072d","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-005","location":"docs/plan/axel-project-plan.md:1715","current":"결정: Re-embed (gemini-embedding-001, 768d)","expected":"결정: Re-embed (gemini-embedding-001, 3072d)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-006","location":"docs/plan/axel-project-plan.md:1721","current":"768d 차원 유지 → pgvector 컬럼 타입 변경 불필요","expected":"3072d로 변경 — pgvector 컬럼 타입 vector(3072)으로 변경 필요","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-007","location":"docs/plan/axel-project-plan.md:2023","current":"ADR-016 | Embedding Model: gemini-embedding-001 (768d)","expected":"ADR-016 | Embedding Model: gemini-embedding-001 (3072d)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-008","location":"docs/plan/axel-project-plan.md:2038","current":"gemini-embedding-001 (768d) — ADR-016","expected":"gemini-embedding-001 (3072d) — ADR-016","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-009","location":"docs/plan/axel-project-plan.md:301","current":"readonly dimension: number; // e.g., 768","expected":"readonly dimension: number; // e.g., 3072","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-010","location":"docs/adr/016-embedding-model-selection.md:20","current":"gemini-embedding-001 (768d, Matryoshka truncation) 사용","expected":"gemini-embedding-001 (3072d, full dimension) 사용. Mark의 결정으로 truncation 사용하지 않음.","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-011","location":"docs/adr/016-embedding-model-selection.md:36-48","current":"Dimension Choice: 768d 섹션 전체 (768d 선택 근거 4개)","expected":"Dimension Choice: 3072d로 변경. 근거: Mark의 결정 — full precision 우선, 저장 공간 trade-off 수용","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-012","location":"docs/adr/016-embedding-model-selection.md:65","current":"readonly dimension: 768;","expected":"readonly dimension: 3072;","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-013","location":"docs/adr/016-embedding-model-selection.md:140","current":"embeddingDimension: z.number().int().default(768)","expected":"embeddingDimension: z.number().int().default(3072)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-014","location":"docs/adr/013-six-layer-memory-architecture.md:143","current":"Gemini embedding-001 (768d)","expected":"Gemini embedding-001 (3072d)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-015","location":"docs/adr/002-postgresql-single-db.md:36","current":"memories + vector(768) — Semantic Memory (Layer 3, pgvector)","expected":"memories + vector(3072) — Semantic Memory (Layer 3, pgvector)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-016","location":"docs/plan/migration-strategy.md:163","current":"embedding vector(768) NOT NULL","expected":"embedding vector(3072) NOT NULL","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-017","location":"docs/plan/migration-strategy.md:463","current":"Axel uses gemini-embedding-001 (768d, PLAN-001 decision)","expected":"Axel uses gemini-embedding-001 (3072d, HUMAN DIRECTIVE override)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-018","location":"docs/plan/migration-strategy.md:474","current":"Call Gemini gemini-embedding-001 API (768d output)","expected":"Call Gemini gemini-embedding-001 API (3072d output)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-019","location":"docs/plan/v2-open-items-decisions.md:11,15","current":"Embedding Model: gemini-embedding-001 (768d) / 768d, Matryoshka truncation","expected":"gemini-embedding-001 (3072d) / 3072d, full dimension (no truncation)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2000","from":"audit","type":"finding","severity":"HIGH","id":"AUD-020","location":"docs/plan/v2-open-items-decisions.md:176","current":"gemini-embedding-001 (768d)","expected":"gemini-embedding-001 (3072d)","evidence":"HUMAN DIRECTIVE broadcast.jsonl:43"}
{"ts":"0208T2001","from":"audit","type":"finding","severity":"HIGH","id":"AUD-021","location":"docs/adr/016-embedding-model-selection.md:28","current":"Max input tokens | 8,192","expected":"Max input tokens | 2,048","evidence":"Official Google docs: ai.google.dev/gemini-api/docs/embeddings confirms 2,048. The 8,192 figure appears to be from experimental model gemini-embedding-exp-03-07. GA model is 2,048."}
{"ts":"0208T2001","from":"audit","type":"finding","severity":"HIGH","id":"AUD-022","location":"docs/plan/migration-strategy.md:186 vs docs/plan/axel-project-plan.md:787","current":"migration-strategy uses IVFFlat (lists=100) index; plan body uses HNSW (m=16, ef_construction=64) index","expected":"Both should use HNSW as plan body Section 4 Layer 3 specifies. Migration-strategy.md migration 003 is inconsistent.","evidence":"Plan:787 says 'HNSW 권장 (RES-001: 7.4x faster queries, better recall)'. Migration SQL at migration-strategy.md:185-187 creates IVFFlat index instead."}
{"ts":"0208T2001","from":"audit","type":"finding","severity":"MEDIUM","id":"AUD-023","location":"docs/adr/016-embedding-model-selection.md:29","current":"Output dimensions | 3,072 (full) / 768 (truncated) / 256 (truncated)","expected":"Output dimensions | 128-3,072 (flexible). Recommended: 768 / 1,536 / 3,072","evidence":"Official Google docs: supports any integer 128-3072. Recommended values are 768, 1536, 3072. ADR omits 1536 entirely and includes non-recommended 256."}
{"ts":"0208T2001","from":"audit","type":"finding","severity":"MEDIUM","id":"AUD-024","location":"docs/adr/016-embedding-model-selection.md:34","current":"Task types: RETRIEVAL_DOCUMENT, RETRIEVAL_QUERY, SEMANTIC_SIMILARITY, CLASSIFICATION, CLUSTERING (5 types)","expected":"8 task types including CODE_RETRIEVAL_QUERY, QUESTION_ANSWERING, FACT_VERIFICATION","evidence":"Official Google docs: ai.google.dev/gemini-api/docs/embeddings lists 8 task types. ADR-016 missing 3."}
{"ts":"0208T2001","from":"audit","type":"finding","severity":"MEDIUM","id":"AUD-025","location":"docs/adr/016-embedding-model-selection.md:31","current":"MTEB score | 68.32 (#1 ranking, 2026-01 기준)","expected":"MTEB score | 68.16 (3072d GA model) or 68.32 (experimental model). Should clarify which.","evidence":"Google official docs show 768d=67.99, 3072d=68.16 for GA model. 68.32 was the experimental model score (gemini-embedding-exp-03-07)."}
{"ts":"0208T2001","from":"audit","type":"finding","severity":"MEDIUM","id":"AUD-026","location":"docs/research/RES-003-gemini-embedding-comparison.md:65","current":"Single input per request: Cannot batch multiple texts in one API call (batch API coming soon)","expected":"batchEmbedContents endpoint exists and was available at GA launch. Up to 250 texts per request (Vertex AI).","evidence":"Official Google API: models.batchEmbedContents endpoint documented. Vertex AI docs confirm 250 text limit per batch request."}
{"ts":"0208T2001","from":"audit","type":"finding","severity":"MEDIUM","id":"AUD-027","location":"docs/plan/v2-open-items-decisions.md:40-65","current":"PLAN-001 Section 2 says 'React (Vite)' for WebChat","expected":"ADR-017 superseded this to Svelte 5 (SvelteKit). PLAN-001 document not updated.","evidence":"ADR-017 status: PROPOSED. Plan main body at line 259 correctly says 'SvelteKit — ADR-017'. But PLAN-001 (v2-open-items-decisions.md) still says React."}
{"ts":"0208T2001","from":"audit","type":"finding","severity":"MEDIUM","id":"AUD-028","location":"docs/research/RES-003-gemini-embedding-comparison.md:29","current":"Max tokens: 2,048 input tokens","expected":"Correct (2,048). But ADR-016 says 8,192. RES-003 is correct, ADR-016 is wrong.","evidence":"Cross-reference: RES-003:29 correct vs ADR-016:28 incorrect. ADR-016 should have used RES-003 value."}
{"ts":"0208T2002","from":"audit","type":"finding","severity":"MEDIUM","id":"AUD-029","location":"docs/plan/axel-project-plan.md:1721-1722","current":"768d 차원 유지 → pgvector 컬럼 타입 변경 불필요 / 향후 3,072d 업그레이드 가능","expected":"3072d 변경으로 인해 이 두 줄의 논리가 뒤바뀜: 컬럼 타입 변경 필요(768→3072), 업그레이드 불필요(이미 full dim)","evidence":"HUMAN DIRECTIVE 768d→3072d 전환으로 마이그레이션 전략 논리 자체가 변경됨"}
{"ts":"0208T2002","from":"audit","type":"finding","severity":"MEDIUM","id":"AUD-030","location":"docs/plan/migration-strategy.md:180-187","current":"IVFFlat index created with lists=100 for initial ~1,000 vectors. Comment says switch to HNSW at 10,000+","expected":"With 3072d vectors, IVFFlat vs HNSW trade-off changes. 3072d vectors require more memory — HNSW m=16 at 3072d = ~25KB/vector. Storage impact needs recalculation.","evidence":"RES-001 performance data was based on 1536d vectors. 3072d doubles the per-vector storage. IVFFlat lists=100 guidance was for 768d. Needs reassessment for 3072d."}
{"ts":"0208T2002","from":"audit","type":"finding","severity":"LOW","id":"AUD-031","location":"docs/adr/016-embedding-model-selection.md:123","current":"768d로 axnmihn IVFFlat 인덱스 설정(lists=100) 재사용 가능","expected":"3072d 변경 시 이 advantage는 무효. Consequences 섹션 수정 필요.","evidence":"HUMAN DIRECTIVE 768d→3072d. axnmihn 인덱스 설정 재사용 불가."}
{"ts":"0208T2002","from":"audit","type":"finding","severity":"LOW","id":"AUD-032","location":"docs/research/RES-003-gemini-embedding-comparison.md:135","current":"Storage (100K vectors): 1.17 GB (3072-dim) / 293 MB (768-dim)","expected":"Correct values. With 3072d decision, Axel storage for 100K vectors = ~1.17 GB. Plan cost estimates should reflect this.","evidence":"Storage calculation: 3072 × 4 bytes × 100K = ~1.17 GB. This is informational, no error in RES-003."}
{"ts":"0208T2002","from":"audit","type":"finding","severity":"LOW","id":"AUD-033","location":"docs/adr/016-embedding-model-selection.md:68","current":"readonly rateLimitRpm: 1500; // Gemini free tier","expected":"RES-003 reports free tier RPM as 5-15 (post-Dec 2025 cuts). 1500 RPM is paid tier or pre-cut free tier.","evidence":"RES-003:75-76 says 'Free tier RPM: ~5-15 (post-Dec 2025 cuts)'. ADR-016 rateLimitRpm=1500 appears to be paid tier rate or outdated."}
{"ts":"0208T2002","from":"audit","type":"finding","severity":"LOW","id":"AUD-034","location":"docs/research/RES-003-gemini-embedding-comparison.md:64","current":"Max tokens: 2,048 input tokens (lower than text-embedding-004's 3,000 tokens)","expected":"text-embedding-004 max tokens was 2,048, not 3,000. Multiple lines in RES-003 claim 3,000 for text-embedding-004.","evidence":"NEEDS_VERIFICATION — Google deprecated text-embedding-004 docs may no longer be available. RES-003 lines 91,99,129 claim 3,000 tokens for text-embedding-004. Some sources say 2,048. Could not conclusively verify since model is shutdown."}
{"ts":"0208T2003","from":"audit","type":"done","task":"AUDIT-001","findings_high":22,"findings_medium":8,"findings_low":4,"note":"AUDIT-001 완료. 총 34개 findings. HIGH 22건 중 20건은 768d→3072d 차원 변경(Mark 지시), 1건은 ADR-016 max input tokens 오류(8192→2048), 1건은 IVFFlat/HNSW 인덱스 불일치. MEDIUM 8건은 공식 스펙 오류(dimension options, task types, MTEB score, batch API) 및 PLAN-001 React→Svelte 미갱신. LOW 4건은 부수적 영향(인덱스 재사용, 저장공간, rate limit, text-embedding-004 token limit 미확인). Arch Division은 AUD-001~022 (HIGH) 즉시 수정 필요, AUD-023~030 (MEDIUM) 후속 처리 권장."}
