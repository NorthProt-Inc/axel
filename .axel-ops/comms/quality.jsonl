{"ts":"0207T2100","from":"quality","type":"claim","task":"QA-001","note":"v2.0 plan internal consistency verification started"}
{"ts":"0207T2100","from":"quality","type":"claim","task":"QA-002","note":"claude_reports 23 issues mapping completeness verification started"}
{"ts":"0207T2130","from":"quality","type":"issue","sev":"HIGH","ref":"docs/plan/axel-project-plan.md:576","desc":"IVFFlat lists parameter inconsistency: comment says 'lists = sqrt(N)*10' with N=1000 which gives ~316, but actual setting is lists=100","fix":"Either change formula comment to 'lists = sqrt(N)*3' or change lists value to 316. Research (RES-001) should validate optimal lists value for 1K-100K vectors."}
{"ts":"0207T2130","from":"quality","type":"issue","sev":"HIGH","ref":"docs/plan/axel-project-plan.md:399-419","desc":"Zod MemoryConfigSchema missing decay parameters: accessStabilityK, relationResistanceK, channelDiversityK, recencyBoost, recencyAgeThreshold, recencyAccessThreshold are defined in DecayConfig interface (line 798-808) but absent from the Zod config schema","fix":"Add missing decay parameters to MemoryConfigSchema.decay or create a separate DecayConfigSchema that includes all 10 parameters"}
{"ts":"0207T2130","from":"quality","type":"issue","sev":"HIGH","ref":"docs/adr/","desc":"12 ADRs listed as 'confirmed' (ADR-001 through ADR-012) in Section 10 but no ADR files exist in docs/adr/ directory. CONSTITUTION Section 3 requires confirmed ADRs to be append-only documents.","fix":"Architecture Division should create individual ADR documents for all 12 confirmed decisions before plan finalization"}
{"ts":"0207T2131","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:709-763","desc":"Naming collision: Memory layers use 'Layer 0-5' internally while Turtle Stack uses 'Layer 0-10'. Stream Buffer is 'Memory Layer 0' but lives inside 'Turtle Stack Layer 3'. This could cause confusion in distributed agent implementation.","fix":"Rename Memory layers to 'M0-M5' (or 'MemLayer') to distinguish from Turtle Stack layers L0-L10"}
{"ts":"0207T2131","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:980-986,298-300","desc":"Embedding capability defined in two places: LlmProvider.embed() (line 984) and separate EmbeddingService interface (line 298-300). Unclear which is canonical for the DI container.","fix":"Remove embed() from LlmProvider interface. Embedding should be a separate service (EmbeddingService) since not all LLM providers offer embeddings. LlmProvider should focus on chat/completion only."}
{"ts":"0207T2131","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:847-894","desc":"Context Assembler is in packages/core/ but needs data from pgvector and PostgreSQL graph (I/O). Plan says 'core has no I/O' but doesn't explicitly state how Assembler gets data via DI injection.","fix":"Add a note in Section 3.3 that Context Assembler receives data through injected Repository interfaces (MemoryRepository, GraphRepository, SessionRepository), not direct DB access"}
{"ts":"0207T2131","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:790-823","desc":"channelMentions field ambiguity: DecayInput defines it as 'number' (line 791) meaning 'how many channels mentioned this memory', but memories table stores channel_mentions as JSONB (line 567: {\"discord\": 3, \"telegram\": 1}). Is the number the count of distinct channels (2) or sum of all mentions (4)?","fix":"Clarify in DecayInput comment: channelMentions should be the count of distinct channels (Object.keys(channel_mentions).length), not sum of values"}
{"ts":"0207T2132","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:1759-1784","desc":"claude_reports #08 (research_server.py 856-line monolith) has no mapping in Appendix A module mapping table. Research/browse functionality is not addressed in Axel architecture.","fix":"Add research_server.py mapping to Appendix A. Likely maps to infra/mcp/tools/research.ts or a dedicated research service"}
{"ts":"0207T2132","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:69","desc":"claude_reports #13 (IoT device ID hardcoded in 5 files) not addressed in Axel architecture. Phase 3 mentions IoT Bridge but doesn't mention how device IDs will be managed.","fix":"Add IoT device registry to config schema (SecurityConfigSchema or new IotConfigSchema) with device discovery or config-based device list"}
{"ts":"0207T2132","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:75","desc":"claude_reports #21 (XML tag 3x hardcoding, 22/32 registered) not addressed. Axel channels use different message format but the underlying issue of scattered format constants is not resolved.","fix":"Add a note that Axel uses structured OutboundMessage interface (line 1278-1283) which eliminates XML tag hardcoding entirely, or map this to the channel adapter format conversion"}
{"ts":"0207T2132","from":"quality","type":"issue","sev":"LOW","ref":"docs/plan/axel-project-plan.md:1243","desc":"InboundHandler type referenced in AxelChannel.onMessage() but not defined in the plan","fix":"Add type definition: type InboundHandler = (msg: InboundMessage) => Promise<void>"}
{"ts":"0207T2133","from":"quality","type":"done","task":"QA-001","out":"docs/plan/axel-project-plan.md","note":"Found 3 HIGH issues (IVFFlat param, config schema gap, missing ADR files), 5 MEDIUM issues (naming collision, dual embedding, context assembler I/O, channelMentions ambiguity, missing module mappings), 1 LOW issue. Budget arithmetic and MISSION.md compliance passed."}
{"ts":"0207T2133","from":"quality","type":"done","task":"QA-002","out":"docs/plan/axel-project-plan.md","note":"20/23 claude_reports issues have explicit Axel mappings. 3 MEDIUM gaps: #08 (research_server mapping), #13 (IoT device ID management), #21 (XML tag issue). All CRITICAL and HIGH issues are properly addressed."}
{"ts":"0208T0030","from":"quality","type":"claim","task":"QA-003","note":"v2.0 plan feasibility review started — npm packages, version compat, performance claims, Redis drift"}
{"ts":"0208T0035","from":"quality","type":"issue","sev":"HIGH","ref":"docs/plan/axel-project-plan.md:192-197,668-691,710-725,1206-1215","desc":"Redis usage violates 'PostgreSQL single DB' principle (MISSION.md #2). Session Router (line 677) stores active session state exclusively in Redis with no PG fallback — Redis restart breaks cross-channel continuity. Stream Buffer (Layer 0, line 710) is entirely Redis Streams with no PG backup. PubSub (line 678) has at-most-once delivery with no fallback. ADR-002 (single DB) and ADR-003 (Redis for working memory + pub/sub) are in unacknowledged tension.","fix":"1) Redefine ADR-002 as 'single source of truth' — PG is authoritative, Redis is ephemeral acceleration. 2) Add PG shadow table for Session Router active sessions with reconstruction path on Redis miss. 3) Specify Working Memory flush strategy (write-through frequency, error handling). 4) Document Stream Buffer as intentionally ephemeral with graceful degradation. 5) Replace PubSub with Redis Streams consumer groups (ack + replay) or add PG event log fallback. 6) Add 'Relationship to ADR-002' section in ADR-003."}
{"ts":"0208T0035","from":"quality","type":"issue","sev":"HIGH","ref":"docs/plan/axel-project-plan.md:394,558,850","desc":"text-embedding-004 (768d) was deprecated January 2026. Plan references it at lines 394, 558 (vector(768)), and 850. Successor is gemini-embedding-001 (default 3072d, supports output_dimensionality=768 via MRL).","fix":"Update all references from text-embedding-004 to gemini-embedding-001. Decide on dimension: keep 768d (via output_dimensionality param) for migration ease, or upgrade to 3072d for quality. Update pgvector column definition and IVFFlat parameters accordingly."}
{"ts":"0208T0035","from":"quality","type":"issue","sev":"HIGH","ref":"docs/plan/axel-project-plan.md:850-851","desc":"Plan claims 'tiktoken 기반 정확한 토큰 카운팅' (line 850) but tiktoken is for OpenAI tokenization (cl100k_base, o200k_base), NOT for Claude/Anthropic models. @anthropic-ai/tokenizer exists but is stale (v0.0.4, last updated July 2023).","fix":"Use @anthropic-ai/sdk count_tokens API endpoint for Claude models (server-side, always accurate). Use tiktoken for OpenAI/Gemini estimation only. Alternatively, use a per-model tokenizer strategy: { anthropic: sdk.count_tokens(), google: estimate via tiktoken, ollama: model-specific }."}
{"ts":"0208T0036","from":"quality","type":"issue","sev":"HIGH","ref":"docs/plan/axel-project-plan.md:576","desc":"IVFFlat formula 'lists = sqrt(N)*10' is NOT from pgvector docs. Official recommendation: rows/1000 for <1M rows, sqrt(rows) for >1M. For N=1000, official formula gives lists=1 (index provides no benefit). For N=100K, official gives lists=100. With only 1000 vectors, IVFFlat is counterproductive — sequential scan or HNSW is better. This supersedes QA-001 finding on same line with corrected source.","fix":"1) Remove the 'sqrt(N)*10' formula comment entirely. 2) For <10K vectors: skip IVFFlat, use sequential scan. 3) For 10K-100K: use lists=rows/1000. 4) Consider HNSW as default index (pgvector docs increasingly recommend it). 5) RES-001 should validate with actual benchmarks."}
{"ts":"0208T0036","from":"quality","type":"issue","sev":"HIGH","ref":"docs/plan/axel-project-plan.md:1022-1029","desc":"Gemini Flash intent classification claim '<50ms' (line 1022) is not achievable via API. Gemini Flash TTFT is ~300ms minimum (API network RTT alone is 20-80ms). Sub-50ms requires a local model, not an external API call.","fix":"Either: 1) Revise latency target to '<500ms' for API-based classification, or 2) Use a local lightweight classifier (e.g., ONNX runtime with a small model) for the <50ms target, with Gemini Flash as fallback for ambiguous cases."}
{"ts":"0208T0036","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:380-475","desc":"Zod v4 (current latest: 4.3.6) has breaking API changes from v3. Plan's Zod schema examples may have been written against v3 API. Key changes: .transform(), .refine(), schema inference behavior.","fix":"Verify all Zod schema examples in Section 4 Layer 1 compile under Zod v4. Pin Zod version in package.json or update examples if needed."}
{"ts":"0208T0036","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:983","desc":"LlmProvider.embed() method (line 983) should be removed per QA-001 finding, but also: LlmProvider.countTokens() is model-specific and cannot be a simple synchronous function for all providers. Anthropic requires an API call (count_tokens endpoint), while tiktoken is synchronous. The interface conflates sync and async token counting.","fix":"Change countTokens to async: countTokens(text: string): Promise<number>. Or split into estimateTokens (sync, approximate) and countTokens (async, exact via API)."}
{"ts":"0208T0036","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:1685-1686","desc":"'모든 응답의 첫 토큰이 500ms 이내' (line 1686) is achievable at p50 but not as a reliable guarantee. End-to-end pipeline: Redis (~1ms) + pgvector (~20ms) + context assembly (~5ms) + LLM TTFT (~300-800ms variable). Realistic: p50 ~400-500ms, p95 ~700-1000ms.","fix":"Revise success criterion to '첫 토큰 500ms p50, 1000ms p95' or specify that 500ms applies only to cached/simple responses. Aggressive caching of common intents can help meet tighter targets."}
{"ts":"0208T0036","from":"quality","type":"issue","sev":"MEDIUM","ref":"docs/plan/axel-project-plan.md:1697","desc":"Docker cold start '<30s' (line 1697) is realistic only with cached images. First deployment with image pulls + pgvector extension initialization will exceed 30s.","fix":"Add qualifier: '<30s with cached images'. First deployment target should be separate (e.g., <120s)."}
{"ts":"0208T0036","from":"quality","type":"issue","sev":"LOW","ref":"docs/plan/axel-project-plan.md:340","desc":"tsdown is from the Rolldown ecosystem (github.com/rolldown/tsdown), not 'OpenClaw'. The plan says 'OpenClaw 동일' for tsdown, but this refers to the build tool choice, not the source. Minor reference accuracy issue.","fix":"Clarify: 'OpenClaw uses tsdown (Rolldown ecosystem)' — the reference is to tool choice alignment, not origin."}
{"ts":"0208T0037","from":"quality","type":"done","task":"QA-003","out":"docs/plan/axel-project-plan.md","note":"Feasibility review complete. Found 5 HIGH issues (Redis single-DB drift, deprecated embedding model, tiktoken wrong for Claude, IVFFlat formula correction, Gemini Flash latency claim), 4 MEDIUM issues (Zod v4 compat, countTokens sync/async, TTFT target, Docker cold start qualifier), 1 LOW (tsdown attribution). All npm packages verified to exist and be maintained. Node.js 22 compatibility confirmed for all."}
